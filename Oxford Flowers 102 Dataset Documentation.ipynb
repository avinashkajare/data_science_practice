{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ba4332e"
      },
      "source": [
        "# Transfer Learning on Oxford Flowers 102 Dataset Documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsZFaJzx8xtH"
      },
      "source": [
        "## 1. Data Loading and Preprocessing\n",
        "Load the Flowers-102 dataset and prepare it for transfer learning by applying appropriate preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Load the dataset\n",
        "data, info = tfds.load('oxford_flowers102', with_info=True, as_supervised=True)\n",
        "train_data, test_data = data['train'], data['test']"
      ],
      "metadata": {
        "id": "LkejYoRbP--Q"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "train_data = train_data.map(preprocess).shuffle(1000).batch(32)\n",
        "test_data = test_data.map(preprocess).batch(32)"
      ],
      "metadata": {
        "id": "qiOpku5pSZKi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaz94rVB8xtI"
      },
      "source": [
        "## 2. Model Preparation\n",
        "Load and modify pre-trained models to fit the Flowers-102 classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBs9PdAu8xtI"
      },
      "source": [
        "### 2.1 Using ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Oy0srMxN8xtI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# Load pre-trained ResNet50 model without the top layer\n",
        "base_model_resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model_resnet50.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(102, activation='softmax')(x)\n",
        "\n",
        "model_resnet50 = Model(inputs=base_model_resnet50.input, outputs=predictions)\n",
        "\n",
        "model_resnet50.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG3ZpE618xtI"
      },
      "source": [
        "### 2.2 Using VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "uoOfgJMD8xtI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# Load pre-trained VGG16 model without the top layer\n",
        "base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "# Add new layers\n",
        "x = GlobalAveragePooling2D()(base_model_vgg16.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(102, activation='softmax')(x)\n",
        "model_vgg16 = Model(inputs=base_model_vgg16.input, outputs=predictions)\n",
        "\n",
        "model_vgg16.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPvKjypT8xtJ"
      },
      "source": [
        "### 2.3 Using MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "NVE5QT-r8xtJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# Load pre-trained MobileNetV2 model without the top layer\n",
        "base_model_mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "# Add new layers\n",
        "x = GlobalAveragePooling2D()(base_model_mobilenetv2.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(102, activation='softmax')(x)\n",
        "model_mobilenetv2 = Model(inputs=base_model_mobilenetv2.input, outputs=predictions)\n",
        "\n",
        "model_mobilenetv2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4LO5ynU8xtJ"
      },
      "source": [
        "## 3. Fine-Tuning and Training\n",
        "Unfreeze some of the top layers of the pre-trained models and continue training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5ElWybb8xtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22cee1ad-f0fd-400a-9989-2e9561567d3a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "178\n",
            "22\n",
            "157\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x7f5608784400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.0090 - loss: 4.9114"
          ]
        }
      ],
      "source": [
        "epochs = 3\n",
        "\n",
        "print(len(model_resnet50.layers))\n",
        "print(len(model_vgg16.layers))\n",
        "print(len(model_mobilenetv2.layers))\n",
        "\n",
        "\n",
        "# Fine-tuning ResNet50\n",
        "for layer in model_resnet50.layers[:-30]:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in model_resnet50.layers[-30:]:\n",
        "    layer.trainable = True\n",
        "    history_resnet50    = model_resnet50.fit(train_data, epochs=epochs, validation_data=test_data)\n",
        "\n",
        "\n",
        "\n",
        "# Fine-tuning VGG16\n",
        "for layer in model_vgg16.layers[:-5]:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in model_vgg16.layers[-5:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "history_vgg16       = model_vgg16.fit   (train_data, epochs=epochs, validation_data=test_data)\n",
        "\n",
        "\n",
        "\n",
        "# Fine-tuning MobileNetV2\n",
        "for layer in model_mobilenetv2.layers[:-40]:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in model_mobilenetv2.layers[-40:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "history_mobilenetv2 = model_mobilenetv2.fit (train_data, epochs=epochs, validation_data=test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAJbqP6T8xtJ"
      },
      "source": [
        "## 4. Model Evaluation\n",
        "Evaluate each model on the test dataset to compare their performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyEKFHnS8xtJ"
      },
      "outputs": [],
      "source": [
        "acc_resnet50    = model_resnet50.evaluate(test_data)[1]\n",
        "acc_vgg16       = model_vgg16.evaluate(test_data)[1]\n",
        "acc_mobilenetv2 = model_mobilenetv2.evaluate(test_data)[1]\n",
        "\n",
        "print(f'ResNet50 Accuracy: {acc_resnet50:.2f}')\n",
        "print(f'VGG16 Accuracy: {acc_vgg16:.2f}')\n",
        "print(f'MobileNetV2 Accuracy: {acc_mobilenetv2:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Resnet50 is giving better accuracy **"
      ],
      "metadata": {
        "id": "VALJpsSVlMqt"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}